# Waggle â€” Project Context

> Last updated: 2026-02-15

## What This Is

A multi-agent orchestration framework in Go. A central **Queen** agent decomposes objectives into tasks, delegates them to **Worker Bee** sub-agents running via coding CLI tools, monitors execution, reviews results with LLM judgment, and reports findings back to the user.

Think of it as a task runner where the tasks are executed by AI coding agents in parallel, with an AI reviewer ensuring quality.

## Architecture

```bash
User Objective
       â”‚
   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”
   â”‚ Queen â”‚  Autonomous tool-using LLM agent (agent mode)
   â”‚       â”‚  OR Plan â†’ Delegate â†’ Monitor â†’ Review â†’ Replan (legacy mode)
   â””â”€â”€â”€â”¬â”€â”€â”€â”˜
       â”‚ spawns via adapters (with safety guard + scope constraints)
   â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â–¼                â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”
â”‚Workerâ”‚      â”‚Workerâ”‚      â”‚Workerâ”‚   (parallel, ephemeral)
â”‚(kimi)â”‚      â”‚(kimi)â”‚      â”‚(exec)â”‚
â””â”€â”€â”¬â”€â”€â”€â”˜      â””â”€â”€â”¬â”€â”€â”€â”˜      â””â”€â”€â”¬â”€â”€â”€â”˜
   â”‚              â”‚              â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
            â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
            â”‚ Blackboard â”‚  shared results
            â”‚  SQLite DB â”‚  persistent state
            â”‚  Event Log â”‚  append-only audit
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚      TUI Dashboard          â”‚
   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
   â”‚  â”‚ ğŸ‘‘ Queen / âš™ Worker  â”‚   â”‚  Tab to switch panels,
   â”‚  â”‚  live streaming       â”‚   â”‚  real-time output
   â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
   â”‚  â”‚ ğŸ“‹ Task Panel         â”‚   â”‚  Task status, worker
   â”‚  â”‚  status / workers     â”‚   â”‚  assignments, progress
   â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
   â”‚  â”‚ ğŸ Status Bar         â”‚   â”‚  Elapsed, worker count
   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Two Execution Modes

### Agent Mode (default when provider supports tools)

The Queen runs as an autonomous tool-using LLM agent. She receives the objective, and the Go code just executes tool calls and feeds results back. The Queen decides what tools to call and when: `create_tasks`, `assign_task`, `wait_for_workers`, `get_task_output`, `approve_task`, `reject_task`, `read_file`, `list_files`, `complete`, `fail`.

### Legacy Mode (fallback / `--legacy` flag)

The structured Plan â†’ Delegate â†’ Monitor â†’ Review â†’ Replan loop. The Queen's LLM is called at specific phases (planning, review, replan) with structured prompts. After review, skips back to Delegate if ready tasks exist (avoids unnecessary re-planning).

## Module Map

| Package | File(s) | Purpose |
|---------|---------|--------|
| `cmd/waggle` | `main.go`, `app.go`, `commands.go`, `status.go`, `tasks.go` | CLI entry point (urfave/cli): `run`, `init`, `status`, `config`, `resume` |
| `internal/queen` | `queen.go` | **Core orchestrator** â€” main loop, initialization, logging |
| `internal/queen` | `delegate.go` | Legacy delegation phase â€” assigns ready tasks to workers |
| `internal/queen` | `planner.go` | Legacy planning phase â€” LLM-backed task decomposition + parsing |
| `internal/queen` | `failure.go` | Task failure handling with error classification + retry backoff |
| `internal/queen` | `reporter.go` | Completion reporting â€” task result formatting + summary |
| `internal/queen` | `agent.go` | **Agent mode** â€” autonomous tool-using LLM loop with conversation history |
| `internal/queen` | `tools.go` | Tool definitions + handlers (create_tasks, assign_task, wait, approve, etc.) |
| `internal/queen` | `prompt.go` | System prompt builder for agent mode |
| `internal/queen` | `review.go` | LLM-backed review: evaluates worker output quality |
| `internal/queen` | `replan.go` | LLM-backed replan: identifies follow-up tasks |
| `internal/llm` | `client.go`, `types.go` | **Provider-agnostic LLM client** + `ToolClient` interface |
| `internal/llm` | `anthropic.go` | Anthropic API client with tool-use |
| `internal/llm` | `openai.go` | OpenAI-compatible API client with tool-use |
| `internal/llm` | `gemini.go` | Google Gemini API client with tool-use |
| `internal/llm` | `cli.go` | CLI-based LLM wrapper (no tool support) |
| `internal/llm` | `factory.go` | Provider factory: anthropic, openai, gemini, codex, kimi, gemini-cli, claude-cli, opencode |
| `internal/tui` | `model.go`, `view.go`, `styles.go`, `events.go`, `bridge.go` | **Bubble Tea TUI dashboard** â€” Queen/worker/task panels with live streaming |
| `internal/worker` | `worker.go` | `Bee` interface + concurrent `Pool` with per-task timeout enforcement |
| `internal/adapter` | `generic.go` | **`CLIAdapter` + `CLIWorker`** â€” shared base for all CLI adapters with 3 prompt modes |
| `internal/adapter` | `claude.go`, `kimi.go`, `codex.go`, `opencode.go`, `gemini.go`, `exec.go` | Thin constructors (23-29 lines each) configuring `CLIAdapter` |
| `internal/adapter` | `adapter.go` | `Registry` + `TaskRouter` (maps task types â†’ configured default adapter) |
| `internal/adapter` | `utils.go` | `streamWriter` (live output with max size cap), `buildPrompt()`, `getExitCode()` |
| `internal/bus` | `bus.go` | In-process pub/sub message bus with panic-safe handler dispatch |
| `internal/blackboard` | `blackboard.go` | Shared memory â€” workers post results, Queen reads. History capped at 10k entries. |
| `internal/state` | `db.go` | **SQLite persistence** â€” sessions, events, tasks, blackboard, kv |
| `internal/task` | `task.go` | Task graph with dependency tracking, priority, status, cycle detection, `RetryAfter` backoff |
| `internal/config` | `config.go` | Configuration with defaults, JSON serialization |
| `internal/safety` | `safety.go` | Path allowlisting, command blocklisting â€” enforced in all adapters |
| `internal/compact` | `compact.go` | Context window management, token estimation, summarization |
| `internal/errors` | `errors.go` | Error classification, retry/permanent types, jittered exponential backoff |

**Total: ~9,600 lines of source + ~12,600 lines of tests across 22,200 total Go lines (64 commits)**

## Key Interfaces

### `worker.Bee` â€” What every worker must implement

```go
type Bee interface {
    ID() string
    Type() string
    Spawn(ctx context.Context, t *task.Task) error
    Monitor() Status  // idle, running, stuck, complete, failed
    Result() *task.Result
    Kill() error
    Output() string   // Returns live streaming output during execution
}
```

### `adapter.Adapter` â€” How CLIs are wrapped

```go
type Adapter interface {
    Name() string
    Available() bool
    CreateWorker(id string) worker.Bee
}
```

All 6 adapters share `CLIAdapter` + `CLIWorker` from `generic.go`. Three `PromptMode` options:
- `PromptAsArg` â€” append prompt as last CLI argument (claude, kimi, codex, opencode)
- `PromptOnStdin` â€” pipe prompt to stdin (gemini)
- `PromptAsScript` â€” run task description as `bash -c` script (exec)

### `llm.Client` â€” Provider-agnostic LLM interface

```go
type Client interface {
    Chat(ctx context.Context, systemPrompt, userMessage string) (string, error)
    ChatWithHistory(ctx context.Context, systemPrompt string, messages []Message) (string, error)
}
```

### `llm.ToolClient` â€” LLM with tool-use support (extends Client)

```go
type ToolClient interface {
    Client
    ChatWithTools(ctx context.Context, system string, messages []ToolMessage, tools []ToolDef) (*Response, error)
}
```

Implementations: `AnthropicClient`, `OpenAIClient`, `GeminiClient` (all tool-capable), `CLIClient` (no tools, triggers legacy mode).

## Queen's Agent Tools

| Tool | Purpose |
|------|--------|
| `create_tasks` | Create tasks in the task graph with types, priorities, dependencies, constraints |
| `assign_task` | Assign a pending task to a worker (respects deps, pool capacity, configured adapter) |
| `wait_for_workers` | Block until one or more workers complete (with timeout) |
| `get_status` | Get current status of all tasks |
| `get_task_output` | Read a completed/failed task's output |
| `approve_task` | Mark a completed task as approved |
| `reject_task` | Reject a task with feedback, re-queue for retry |
| `read_file` | Read a file from the project (safety-checked) |
| `list_files` | List directory contents |
| `complete` | Declare the objective complete with summary |
| `fail` | Declare the objective failed with reason |

## TUI Dashboard

Bubble Tea-based terminal UI with switchable panels:

- **Queen Panel** â€” Real-time display of Queen's thinking, tool calls, and results. Scrollable (j/k, arrows). Scroll clamped so content is always visible.
- **Worker Panels** â€” Live streaming output from each active worker. Tab/Shift+Tab to cycle, â†â†’ to navigate, 0 to return to Queen.
- **Task Panel** â€” Task list with status icons (â³ pending, ğŸ”„ running, âœ… complete, âŒ failed), worker assignments.
- **Status Bar** â€” Elapsed time, active worker count, navigation hints.

The TUI auto-detects TTY. Falls back to plain log output with `--plain`. After completion, waits for user keypress before exiting. Interactive mode (no args) shows an objective prompt.

### Output Streaming

All adapters use `streamWriter` (thread-safe `io.MultiWriter` tee) to write process stdout/stderr to `w.output` in real-time. Output capped at `workers.max_output_size` (default 1MB) â€” truncation marker appended when exceeded. The TUI polling goroutine sends `WorkerOutputMsg` every 500ms.

### Bridge

The bridge (`tui/bridge.go`) routes log output from the Queen into structured TUI messages, with message buffering for events that arrive before the TUI starts. Supports quiet mode (`NewQuietProgram()`).

## Task Execution Model

### Parallelism
- **Planning prompt** tells the LLM planner the worker count and instructs it to minimize dependencies
- **Agent mode prompt** instructs the Queen to assign ALL ready tasks before waiting
- **Legacy mode** Reviewâ†’Delegate shortcut: when review finds ready tasks, skips back to delegation
- **Worker pool** enforces `max_parallel` limit; `assign_task` returns error when full

### Per-Worker Timeout
- `Pool.Spawn` wraps context with `context.WithTimeout(ctx, task.Timeout)` when `Timeout > 0`
- `exec.CommandContext` kills the process when the deadline expires
- `CLIWorker` detects `context.DeadlineExceeded` and reports `[timeout] worker killed`
- Bus event `MsgWorkerFailed` published on timeout
- Default timeout: 10 minutes (from `workers.default_timeout`)

### Task Retry with Backoff
- Failed tasks get `RetryAfter` set using jittered exponential backoff
- `TaskGraph.Ready()` skips tasks whose `RetryAfter` hasn't elapsed
- Max retries configurable per-task and globally via `workers.max_retries`

## Provider Selection

Configured via `waggle.json`:

```json
{"queen": {"provider": "anthropic"}}   // Anthropic API (tool-use, needs ANTHROPIC_API_KEY)
{"queen": {"provider": "openai"}}      // OpenAI API (tool-use, needs OPENAI_API_KEY)
{"queen": {"provider": "gemini-api"}}  // Gemini API (tool-use, needs GEMINI_API_KEY)
{"queen": {"provider": "codex"}}       // Codex (tool-use via OpenAI-compatible API)
{"queen": {"provider": "kimi"}}        // Kimi CLI (no tool-use, legacy mode)
{"queen": {"provider": "claude-cli"}}  // Claude CLI (no tool-use, legacy mode)
{"queen": {"provider": "opencode"}}    // OpenCode CLI (no tool-use, legacy mode)
```

## Scope Constraints System

Three layers control what workers can and cannot do:

1. **Plan prompt** â€” narrowly-scoped tasks with `constraints` and `allowed_paths`
2. **Default constraints** â€” injected via `injectDefaultConstraints()` at delegation: no out-of-scope changes, no unsolicited refactoring, no signature changes
3. **Worker prompt** â€” `buildPrompt()` renders `--- SCOPE CONSTRAINTS ---` block

## Safety Guard

`safety.Guard` wired into all adapter constructors, enforced at spawn time:
- `ValidateTaskPaths()`, `CheckCommand()`, `IsReadOnly()`, `CheckFileSize()`
- All adapter goroutines have `defer/recover` for panic safety

## Persistence Layer

```
.hive/
â””â”€â”€ hive.db       # SQLite (WAL mode) â€” sole persistence store
```

### SQLite Schema
- **sessions** â€” one row per `waggle run` invocation
- **events** â€” append-only event log indexed by session + type
- **tasks** â€” full task state (status, worker_id, result JSON, retries, deps)
- **blackboard** â€” persisted shared memory (key/value per session)
- **kv** â€” general purpose key-value store (agent conversation turns)

## CLI Commands

```bash
waggle init                          # Create .hive/ and waggle.json
waggle run "<objective>"              # Run with AI planning (TUI if TTY)
waggle                               # Interactive TUI mode (prompts for objective)
waggle --adapter kimi run "<obj>"     # Specify worker adapter
waggle --adapter exec --tasks f.json run "<obj>"  # Pre-defined tasks
waggle --workers 8 run "<obj>"        # Set parallelism
waggle --plain run "<obj>"            # Force plain log output (no TUI)
waggle --legacy run "<obj>"           # Force legacy orchestration loop
waggle --quiet run "<obj>"            # Suppress all output except errors
waggle --json run "<obj>"             # Output results as JSON
waggle status                         # Show current/last session
waggle config                         # Show configuration
waggle resume <session-id>            # Resume interrupted session
```

## Build & Development

```bash
just build              # Build ./waggle binary
just test               # Run all tests
just test-pkg queen     # Test specific package
just test-race          # Tests with race detector
just ci                 # fmt-check + vet + test
just run "<obj>"        # Build & run with objective
just run-interactive    # Launch TUI prompt
just fmt                # Format all Go files
just clean              # Remove binary + .hive/
```

## Configuration (`waggle.json`)

```json
{
  "queen": {
    "provider": "anthropic",
    "model": "claude-sonnet-4-20250514",
    "max_iterations": 50,
    "plan_timeout": 300000000000,
    "review_timeout": 120000000000,
    "compact_after_messages": 100
  },
  "workers": {
    "max_parallel": 4,
    "default_timeout": 600000000000,
    "max_retries": 2,
    "default_adapter": "claude-code",
    "max_output_size": 1048576
  },
  "adapters": { ... },
  "safety": {
    "allowed_paths": ["."],
    "blocked_commands": ["rm -rf /", "sudo rm"],
    "max_file_size": 10485760
  }
}
```

## Adapters â€” Current State

| Adapter | CLI | Status |
|---------|-----|--------|
| `kimi` | `kimi --print --final-message-only -p "<prompt>"` | âœ… Working (rate-limited on this VM) |
| `opencode` | `opencode run "<prompt>"` | âœ… Working |
| `gemini` | `echo "<prompt>" \| gemini` | ğŸ”‘ Needs capacity |
| `claude-code` | `claude -p "<prompt>"` | ğŸ”‘ Needs `/login` on this VM |
| `codex` | `codex exec "<prompt>"` | âœ… Working |
| `exec` | `bash -c "<description>"` | âœ… Always available |

**Note**: On this VM, kimi is rate-limited and claude-code needs login. No API keys are set for Anthropic/OpenAI/Gemini. The exec adapter always works for testing.

## Test Coverage

| Package | Tests | Status |
|---------|-------|--------|
| `adapter` | Functionality, safety integration, prompt building, stream writer | âœ… |
| `blackboard` | Post/Read, List, Delete, History, Watch, concurrency | âœ… |
| `bus` | Publish, Subscribe, panic recovery | âœ… |
| `compact` | Context lifecycle, compaction, token estimation, summarizer | âœ… |
| `config` | Defaults, Load/Save roundtrip, HivePath, output modes | âœ… |
| `errors` | Classification, backoff, jitter, panic recovery | âœ… |
| `llm` | Provider types, tool definitions | âœ… |
| `queen` | Agent mode, tools (11), orchestrator loop, review, replan, prompts | âœ… |
| `safety` | Guard creation, path/command/filesize checks, task validation | âœ… |
| `state` | SQLite CRUD, sessions, tasks, events, kv | âœ… |
| `task` | Graph, dependencies, cycle detection, status, ready | âœ… |
| `worker` | Pool lifecycle, spawn, timeout, kill, concurrency | âœ… |
| `cmd/waggle` | âŒ No tests |
| `output` | âŒ No tests |
| `tui` | âŒ No tests |

**12,600 lines of tests across 30 test files. All passing.**

## What Was Tested End-to-End

1. **exec adapter** â€” parallel shell tasks with dependencies (4 tasks, 2 waves) âœ…
2. **opencode adapter** â€” 15-task code review, 3 waves, 12/15 completed âœ…
3. **kimi adapter** â€” 5-task codebase review, 2 waves, all completed ~3min âœ…
4. **Pre-defined tasks** (`--tasks file.json`) with dependency ordering âœ…
5. **Scope constraints** â€” workers stayed in allowed paths âœ…
6. **LLM review + replan** â€” approved tasks, replan returned 0 new tasks âœ…
7. **Agent mode** â€” Queen as autonomous tool-using agent âœ…
8. **TUI dashboard** â€” real-time Queen/worker/task display âœ…
9. **Waggle on itself** â€” framework planned 5 tasks, delegated in parallel waves of 4 âœ…

## Known Issues

- On this VM: kimi rate-limited, claude-code needs `/login`, no API keys set
- CI workflow needs PAT with `workflow` scope to push (was pushed by user)
- Disk space can run low (~19GB total) â€” run `go clean -cache` if needed

## Dependencies

- `modernc.org/sqlite` â€” pure Go SQLite driver (no CGO)
- `github.com/anthropics/anthropic-sdk-go` â€” Anthropic API client
- `github.com/urfave/cli/v3` â€” CLI framework
- `github.com/charmbracelet/bubbletea` â€” TUI framework
- `github.com/charmbracelet/lipgloss` â€” TUI styling
- `golang.org/x/term` â€” TTY detection
- Go 1.26+

## Repository

- GitHub: <https://github.com/HexSleeves/waggle>
- 64 commits on `main`
- Build: `just build` / `just ci`
- CI: GitHub Actions (fmt-check + vet + test + build on push/PR)
- No releases yet
